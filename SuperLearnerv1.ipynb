{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "740355ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import minimize \n",
    "from scipy.optimize import nnls \n",
    "# NOTE: THIS CODE ONLY WORKS FOR UNI-DIMENSIONAL OUTPUT (REGRESSION OR CLASSIFICATION)\n",
    "\n",
    "N = 1000\n",
    "output = 'cls'  # 'cls' for classification 'proba' for probabilities, 'reg' for regression\n",
    "k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e8686bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=N, n_features=8, n_clusters_per_class=4,\n",
    "                            n_informative=4, n_redundant=0, hypercube=False,\n",
    "                            random_state=0, shuffle=True, class_sep=0.1)\n",
    "\n",
    "def fn(x, A, b):\n",
    "    return np.linalg.norm(A.dot(x) - b)\n",
    "\n",
    "def combiner_solve(x, y):\n",
    "    # adapted from https://stackoverflow.com/questions/33385898/how-to-include-constraint-to-scipy-nnls-function-solution-so-that-it-sums-to-1/33388181\n",
    "    beta_0, rnorm = nnls(x,y)\n",
    "    cons = {'type': 'eq', 'fun': lambda x:  np.sum(x)-1}\n",
    "    bounds = [[0.0,None]]*x.shape[1]\n",
    "    minout = minimize(fn, beta_0, args=(x, y), method='SLSQP',bounds=bounds,constraints=cons)\n",
    "    beta = minout.x\n",
    "    return beta\n",
    "\n",
    "class SuperLearner(object):\n",
    "    def __init__(self, output, est_dict, k):\n",
    "        self.k = k  # number of cross validation folds\n",
    "        self.beta = None\n",
    "        self.trained_superlearner = None\n",
    "        self.output = output\n",
    "        self.est_dict = est_dict  # dictionary of learners/algos\n",
    "        \n",
    "    def train_combiner(self, x, y):\n",
    "        if (self.output == 'cls') or (self.output=='proba'):\n",
    "            num_classes = np.unique(y)\n",
    "            if len(num_classes) == 2:\n",
    "                num_classes = 1\n",
    "            elif len(num_classes) > 2:\n",
    "                num_classes = len(num_classes)\n",
    "        else:\n",
    "            num_classes = 1\n",
    "\n",
    "        all_preds = np.zeros((len(y), num_classes, len(self.est_dict)))\n",
    "        all_gts = np.zeros(len(y))\n",
    "        risks = []\n",
    "\n",
    "        i = 0\n",
    "        for key in self.est_dict.keys():\n",
    "\n",
    "            kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "            probs = []\n",
    "            preds = []\n",
    "            gts = []\n",
    "\n",
    "            for train_index, test_index in kf.split(x):\n",
    "                x_train = x[train_index]\n",
    "                x_test = x[test_index]\n",
    "                y_train = y[train_index]\n",
    "                y_test = y[test_index]\n",
    "\n",
    "                est = self.est_dict[key]\n",
    "                est.fit(x_train, y_train)\n",
    "\n",
    "                if self.output == 'proba' or (self.output == 'cls'):\n",
    "                    p = est.predict(x_test)\n",
    "                    p_robs = est.predict_proba(x_test)\n",
    "                    preds.append(p)\n",
    "                    probs.append(p_robs)\n",
    "                elif (self.output == 'reg'):\n",
    "                    p = est.predict(x_test)\n",
    "                    preds.append(p)\n",
    "                gts.append(y_test)\n",
    "\n",
    "            preds = np.concatenate(preds)\n",
    "            probs = np.concatenate(probs)\n",
    "            if num_classes == 1:\n",
    "                probs = probs[:,1].reshape(-1,1)\n",
    "                preds = preds.reshape(-1,1)\n",
    "\n",
    "            gts = np.concatenate(gts)\n",
    "\n",
    "            if (self.output == 'cls') or (self.output == 'proba'):\n",
    "                all_preds[:,:,i] = probs\n",
    "            elif self.output == 'reg':\n",
    "                all_preds[:,:,i] = preds\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        beta = combiner_solve(all_preds[:,0,:],gts)\n",
    "        self.beta = beta\n",
    "        return beta \n",
    "\n",
    "\n",
    "    def train_superlearner(self, x, y):\n",
    "        assert self.beta is not None, 'Train combiner first using SuperLearner.train_combiner(x,y)'\n",
    "        # now we have the coefficients we can retrain the networks on all the data and apply this weighting\n",
    "        risks = []\n",
    "        trained_superlearner = {}\n",
    "\n",
    "        for key in self.est_dict.keys():\n",
    "\n",
    "            est = self.est_dict[key]\n",
    "            est.fit(x, y)\n",
    "            trained_superlearner[key] = est\n",
    "        self.trained_superlearner = trained_superlearner\n",
    "        return trained_superlearner\n",
    "\n",
    "  \n",
    "    def estimation(self, x, y):\n",
    "\n",
    "        all_preds = np.zeros((len(y), len(self.trained_superlearner)))\n",
    "        i = 0\n",
    "        for key in self.trained_superlearner.keys():\n",
    "            est = self.trained_superlearner[key]\n",
    "\n",
    "            if (self.output == 'cls') or self.output == 'proba':\n",
    "                preds = est.predict_proba(x)[:, 1]\n",
    "            else:\n",
    "                preds =est.predict(x)\n",
    "            all_preds[:, i] = preds\n",
    "\n",
    "            i += 1\n",
    "        weighted_preds = np.dot(all_preds, self.beta)\n",
    "        weighted_preds = weighted_preds.reshape(-1,1)\n",
    "        return weighted_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4520f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] 0.552\n"
     ]
    }
   ],
   "source": [
    "est_dict = {'LR':LogisticRegression()}\n",
    "\n",
    "SL = SuperLearner(output='cls', est_dict=est_dict, k=k)\n",
    "SL.train_combiner(x,y)\n",
    "SL.train_superlearner(x,y)\n",
    "preds = SL.estimation(x,y)\n",
    "preds = np.round(preds)\n",
    "print(SL.beta, balanced_accuracy_score(y, preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a10663a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.65888855e-17 1.00000000e+00] 0.781\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_dict = {'LR':LogisticRegression(), 'SVC':SVC(probability=True)}\n",
    "SL = SuperLearner(output='cls', est_dict=est_dict, k=k)\n",
    "SL.train_combiner(x,y)\n",
    "SL.train_superlearner(x,y)\n",
    "preds = SL.estimation(x,y)\n",
    "preds = np.round(preds)\n",
    "print(SL.beta, balanced_accuracy_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "330ee806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.68957552e-16 8.37470055e-01 1.62529945e-01] 0.839\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_dict = {'LR':LogisticRegression(), 'SVC':SVC(probability=True), 'RF':RandomForestClassifier()}\n",
    "SL = SuperLearner(output='cls', est_dict=est_dict, k=k)\n",
    "SL.train_combiner(x,y)\n",
    "SL.train_superlearner(x,y)\n",
    "preds = SL.estimation(x,y)\n",
    "preds = np.round(preds)\n",
    "print(SL.beta, balanced_accuracy_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cd0b1297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a22dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223f6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8b2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c988d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "618f24f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a4121b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf69c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c520d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
