{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56f48f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import minimize \n",
    "from scipy.optimize import nnls \n",
    "# NOTE: THIS CODE ONLY WORKS FOR UNI-DIMENSIONAL OUTPUT (REGRESSION OR CLASSIFICATION)\n",
    "\n",
    "# TODO: Constrain the combiner s.t. the coeffs are non-negative and sum to 1.\n",
    "N = 1000\n",
    "output = 'cls'  # 'cls' for classification 'proba' for probabilities, 'reg' for regression\n",
    "k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0ee10913",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=N, n_features=8, n_clusters_per_class=4,\n",
    "                            n_informative=4, n_redundant=0, hypercube=False,\n",
    "                            random_state=0, shuffle=True, class_sep=0.1)\n",
    "\n",
    "def fn(x, A, b):\n",
    "    return np.linalg.norm(A.dot(x) - b)\n",
    "\n",
    "def combiner_solve(x, y):\n",
    "    # adapted from https://stackoverflow.com/questions/33385898/how-to-include-constraint-to-scipy-nnls-function-solution-so-that-it-sums-to-1/33388181\n",
    "    beta_0, rnorm = nnls(x,y)\n",
    "    cons = {'type': 'eq', 'fun': lambda x:  np.sum(x)-1}\n",
    "    bounds = [[0.0,None]]*x.shape[1]\n",
    "    minout = minimize(fn, beta_0, args=(x, y), method='SLSQP',bounds=bounds,constraints=cons)\n",
    "    beta = minout.x\n",
    "    return beta\n",
    "\n",
    "def train_combiner(x, y, est_dict, output):\n",
    "    if (output == 'cls') or (output=='proba'):\n",
    "        num_classes = np.unique(y)\n",
    "        if len(num_classes) == 2:\n",
    "            num_classes = 1\n",
    "        elif len(num_classes) > 2:\n",
    "            num_classes = len(num_classes)\n",
    "    else:\n",
    "        num_classes = 1\n",
    "\n",
    "    all_preds = np.zeros((len(y), num_classes, len(est_dict)))\n",
    "    all_gts = np.zeros(len(y))\n",
    "    risks = []\n",
    "\n",
    "    i = 0\n",
    "    for key in est_dict.keys():\n",
    "\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "        probs = []\n",
    "        preds = []\n",
    "        gts = []\n",
    "\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            x_train = x[train_index]\n",
    "            x_test = x[test_index]\n",
    "            y_train = y[train_index]\n",
    "            y_test = y[test_index]\n",
    "\n",
    "            est = est_dict[key]\n",
    "            est.fit(x_train, y_train)\n",
    "\n",
    "            if output == 'proba' or (output == 'cls'):\n",
    "                p = est.predict(x_test)\n",
    "                p_robs = est.predict_proba(x_test)\n",
    "                preds.append(p)\n",
    "                probs.append(p_robs)\n",
    "            elif (output == 'reg'):\n",
    "                p = est.predict(x_test)\n",
    "                preds.append(p)\n",
    "            gts.append(y_test)\n",
    "\n",
    "        preds = np.concatenate(preds)\n",
    "        probs = np.concatenate(probs)\n",
    "        if num_classes == 1:\n",
    "            probs = probs[:,1].reshape(-1,1)\n",
    "            preds = preds.reshape(-1,1)\n",
    "\n",
    "        gts = np.concatenate(gts)\n",
    "\n",
    "        if (output == 'cls') or (output == 'proba'):\n",
    "            all_preds[:,:,i] = probs\n",
    "        elif output == 'reg':\n",
    "            all_preds[:,:,i] = preds\n",
    "\n",
    "        if (output == 'cls') or (output == 'proba'):\n",
    "            risks.append(balanced_accuracy_score(gts, preds))\n",
    "        elif output == 'reg':\n",
    "            risks.append(r2_score(gts, preds))       \n",
    "        i += 1\n",
    "\n",
    "    beta = combiner_solve(all_preds[:,0,:],gts)\n",
    "    return beta \n",
    "\n",
    "\n",
    "def train_superlearner(x, y, est_dict):\n",
    "    # now we have the coefficients we can retrain the networks on all the data and apply this weighting\n",
    "    risks = []\n",
    "    trained_superlearner = {}\n",
    "    \n",
    "    for key in est_dict.keys():\n",
    "\n",
    "        est = est_dict[key]\n",
    "        est.fit(x, y)\n",
    "        trained_superlearner[key] = est\n",
    "        \n",
    "    return trained_superlearner\n",
    "\n",
    "  \n",
    "def estimation(x, y, beta, trained_superlearner, output):\n",
    "    \n",
    "    all_preds = np.zeros((len(y), len(trained_superlearner)))\n",
    "    i = 0\n",
    "    for key in trained_superlearner.keys():\n",
    "        est = trained_superlearner[key]\n",
    "        \n",
    "        if (output == 'cls') or output == 'proba':\n",
    "            preds = est.predict_proba(x)[:, 1]\n",
    "        else:\n",
    "            preds =est.predict(x)\n",
    "        all_preds[:, i] = preds\n",
    "        \n",
    "        i += 1\n",
    "    weighted_preds = np.dot(all_preds,beta)\n",
    "        \n",
    "    return weighted_preds\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e17cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] 0.552\n"
     ]
    }
   ],
   "source": [
    "est_dict = {'LR':LogisticRegression()}\n",
    "\n",
    "beta =  train_combiner(x, y, est_dict, output)\n",
    "trained_superlearner = train_superlearner(x, y, est_dict)\n",
    "\n",
    "preds = estimation(x, y, beta, trained_superlearner, output)\n",
    "preds = np.round(preds)\n",
    "print(beta, balanced_accuracy_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b35d34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] 0.781\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_dict = {'LR':LogisticRegression(), 'SVC':SVC(probability=True)}\n",
    "\n",
    "beta =  train_combiner(x, y, est_dict, output)\n",
    "trained_superlearner = train_superlearner(x, y, est_dict)\n",
    "preds = estimation(x, y, beta, trained_superlearner, output)\n",
    "preds = np.round(preds)\n",
    "print(beta, balanced_accuracy_score(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "280df8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.80259633 0.19740367] 0.85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_dict = {'LR':LogisticRegression(), 'SVC':SVC(probability=True), 'RF':RandomForestClassifier()}\n",
    "\n",
    "beta =  train_combiner(x, y, est_dict, output)\n",
    "trained_superlearner = train_superlearner(x, y, est_dict)\n",
    "preds = estimation(x, y, beta, trained_superlearner, output)\n",
    "preds = np.round(preds)\n",
    "print(beta, balanced_accuracy_score(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4538f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d784c954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ccc5883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c081bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f32773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4819c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a758848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f14aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
