{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6d5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import minimize \n",
    "from scipy.optimize import nnls \n",
    "# NOTE: THIS CODE ONLY WORKS FOR UNI-DIMENSIONAL OUTPUT (REGRESSION OR CLASSIFICATION)\n",
    "\n",
    "N = 1000\n",
    "output = 'cls'  # 'cls' for classification 'proba' for probabilities, 'reg' for regression\n",
    "k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed1cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=N, n_features=8, n_clusters_per_class=4,\n",
    "                            n_informative=4, n_redundant=0, hypercube=False,\n",
    "                            random_state=0, shuffle=True, class_sep=0.1)\n",
    "\n",
    "def fn(x, A, b):\n",
    "    return np.linalg.norm(A.dot(x) - b)\n",
    "\n",
    "def combiner_solve(x, y):\n",
    "    # adapted from https://stackoverflow.com/questions/33385898/how-to-include-constraint-to-scipy-nnls-function-solution-so-that-it-sums-to-1/33388181\n",
    "    beta_0, rnorm = nnls(x,y)\n",
    "    cons = {'type': 'eq', 'fun': lambda x:  np.sum(x)-1}\n",
    "    bounds = [[0.0,None]]*x.shape[1]\n",
    "    minout = minimize(fn, beta_0, args=(x, y), method='SLSQP',bounds=bounds,constraints=cons)\n",
    "    beta = minout.x\n",
    "    return beta\n",
    "\n",
    "\n",
    "class SuperLearner(object):\n",
    "\tdef __init__(self, output, est_dict, k):\n",
    "\t\tself.k = k  # number of cross validation folds\n",
    "\t\tself.beta = None\n",
    "\t\tself.trained_superlearner = None\n",
    "\t\tself.output = output\n",
    "\t\tself.est_dict = est_dict  # dictionary of learners/algos\n",
    "\t\tself.x_min = None\n",
    "\t\tself.x_max = None\n",
    "\t\tself.x_max_sq = None\n",
    "\n",
    "\tdef train_combiner(self, x, y):\n",
    "\n",
    "\t\tself.x_min = x.min()\n",
    "\t\tself.x_max = x.max()\n",
    "\t\tself.x_max_sq = x.max()**2\n",
    "\n",
    "\t\tif (self.output == 'cls') or (self.output == 'proba'):\n",
    "\t\t\tnum_classes = np.unique(y)\n",
    "\t\t\tif len(num_classes) == 2:\n",
    "\t\t\t\tnum_classes = 1\n",
    "\t\t\telif len(num_classes) > 2:\n",
    "\t\t\t\tnum_classes = len(num_classes)\n",
    "\t\telse:\n",
    "\t\t\tnum_classes = 1\n",
    "\n",
    "\t\tall_preds = np.zeros((len(y), num_classes, len(self.est_dict)))\n",
    "\n",
    "\t\ti = 0\n",
    "\t\tfor key in self.est_dict.keys():\n",
    "\n",
    "\t\t\tkf = KFold(n_splits=self.k, shuffle=True, random_state=0)\n",
    "\n",
    "\t\t\tprobs = []\n",
    "\t\t\tpreds = []\n",
    "\t\t\tgts = []\n",
    "\n",
    "\t\t\tfor train_index, test_index in kf.split(x):\n",
    "\t\t\t\tx_train = x[train_index]\n",
    "\t\t\t\tx_test = x[test_index]\n",
    "\t\t\t\ty_train = y[train_index]\n",
    "\t\t\t\ty_test = y[test_index]\n",
    "\n",
    "\t\t\t\test = self.est_dict[key]\n",
    "\t\t\t\tif key == 'poly':\n",
    "\t\t\t\t\test = LogisticRegression(C=1e2, max_iter=350) if (self.output == 'cls') or (self.output == 'proba') else LinearRegression()\n",
    "\t\t\t\t\tpoly = PolynomialFeatures(2)\n",
    "\t\t\t\t\tx_train = poly.fit_transform(x_train)\n",
    "\t\t\t\t\tx_test = poly.fit_transform(x_test)\n",
    "\t\t\t\t\t# x_train = (2 * (x_train - self.x_min) / (self.x_max_sq - self.x_min)) - 1\n",
    "\t\t\t\t\t# x_test = (2 * (x_test - self.x_min) / (self.x_max_sq - self.x_min)) - 1\n",
    "\n",
    "\n",
    "\t\t\t\test.fit(x_train, y_train)\n",
    "\n",
    "\t\t\t\tif self.output == 'proba' or (self.output == 'cls'):\n",
    "\t\t\t\t\tp = est.predict(x_test)\n",
    "\t\t\t\t\tp_robs = est.predict_proba(x_test)\n",
    "\t\t\t\t\tpreds.append(p)\n",
    "\t\t\t\t\tprobs.append(p_robs)\n",
    "\t\t\t\telif (self.output == 'reg'):\n",
    "\t\t\t\t\tp = est.predict(x_test)\n",
    "\t\t\t\t\tpreds.append(p)\n",
    "\t\t\t\tgts.append(y_test)\n",
    "\n",
    "\t\t\tpreds = np.concatenate(preds)\n",
    "\t\t\tprobs = np.concatenate(probs)\n",
    "\t\t\tif num_classes == 1:\n",
    "\t\t\t\tprobs = probs[:, 1].reshape(-1, 1)\n",
    "\t\t\t\tpreds = preds.reshape(-1, 1)\n",
    "\n",
    "\t\t\tgts = np.concatenate(gts)\n",
    "\n",
    "\t\t\tif (self.output == 'cls') or (self.output == 'proba'):\n",
    "\t\t\t\tall_preds[:, :, i] = probs\n",
    "\t\t\telif self.output == 'reg':\n",
    "\t\t\t\tall_preds[:, :, i] = preds\n",
    "\n",
    "\t\t\ti += 1\n",
    "\n",
    "\t\tbeta = combiner_solve(all_preds[:, 0, :], gts)\n",
    "\t\tself.beta = beta\n",
    "\t\treturn beta\n",
    "\n",
    "\tdef train_superlearner(self, x, y):\n",
    "\t\tassert self.beta is not None, 'Train combiner first using SuperLearner.train_combiner(x,y)'\n",
    "\t\t# now we have the coefficients we can retrain the networks on all the data and apply this weighting\n",
    "\t\ttrained_superlearner = {}\n",
    "\n",
    "\t\tfor key in self.est_dict.keys():\n",
    "\t\t\test = self.est_dict[key]\n",
    "\t\t\tif key == 'poly':\n",
    "\t\t\t\test = LogisticRegression(C=1e2, max_iter=350) if (self.output == 'cls') or (self.output == 'proba') else LinearRegression()\n",
    "\t\t\t\tpoly = PolynomialFeatures(2)\n",
    "\t\t\t\tx_scaled = poly.fit_transform(x)\n",
    "\t\t\t\t# x_scaled = (2 * (x_scaled - self.x_min) / (self.x_max_sq - self.x_min)) - 1\n",
    "\n",
    "\t\t\t\test.fit(x_scaled, y)\n",
    "\t\t\telse:\n",
    "\t\t\t\test.fit(x, y)\n",
    "\t\t\ttrained_superlearner[key] = est\n",
    "\t\tself.trained_superlearner = trained_superlearner\n",
    "\t\treturn trained_superlearner\n",
    "\n",
    "\tdef estimation(self, x, y):\n",
    "\n",
    "\t\tall_preds = np.zeros((len(y), len(self.trained_superlearner)))\n",
    "\t\ti = 0\n",
    "\t\tfor key in self.trained_superlearner.keys():\n",
    "\t\t\test = self.trained_superlearner[key]\n",
    "\t\t\tif key == 'poly':\n",
    "\t\t\t\tpoly = PolynomialFeatures(2)\n",
    "\t\t\t\tx_scaled = poly.fit_transform(x)\n",
    "\t\t\t\t# x_scaled = (2 * (x_scaled - self.x_min) / (self.x_max_sq - self.x_min)) - 1\n",
    "\n",
    "\t\t\tif (self.output == 'cls') or self.output == 'proba':\n",
    "\t\t\t\tpreds = est.predict_proba(x)[:, 1] if key != 'poly' else est.predict_proba(x_scaled)[:, 1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpreds = est.predict(x) if key != 'poly' else est.predict_proba(x_scaled)[:, 1]\n",
    "\t\t\tall_preds[:, i] = preds\n",
    "\n",
    "\t\t\ti += 1\n",
    "\t\tweighted_preds = np.dot(all_preds, self.beta)\n",
    "\t\tweighted_preds = weighted_preds.reshape(-1, 1)\n",
    "\t\treturn weighted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96593919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] 0.552\n"
     ]
    }
   ],
   "source": [
    "est_dict = {'LR':LogisticRegression()}\n",
    "\n",
    "SL = SuperLearner(output='cls', est_dict=est_dict, k=k)\n",
    "SL.train_combiner(x,y)\n",
    "SL.train_superlearner(x,y)\n",
    "preds = SL.estimation(x,y)\n",
    "preds = np.round(preds)\n",
    "print(SL.beta, balanced_accuracy_score(y, preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2248d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.59701721e-17 1.00000000e+00] 0.783\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_dict = {'LR':LogisticRegression(), 'SVC':SVC(probability=True)}\n",
    "SL = SuperLearner(output='cls', est_dict=est_dict, k=k)\n",
    "SL.train_combiner(x,y)\n",
    "SL.train_superlearner(x,y)\n",
    "preds = SL.estimation(x,y)\n",
    "preds = np.round(preds)\n",
    "print(SL.beta, balanced_accuracy_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395668f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.80779126 0.19220874] 0.845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est_dict = {'LR':LogisticRegression(), 'SVC':SVC(probability=True), 'RF':RandomForestClassifier()}\n",
    "SL = SuperLearner(output='cls', est_dict=est_dict, k=k)\n",
    "SL.train_combiner(x,y)\n",
    "SL.train_superlearner(x,y)\n",
    "preds = SL.estimation(x,y)\n",
    "preds = np.round(preds)\n",
    "print(SL.beta, balanced_accuracy_score(y, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3696d9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee5640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4aa5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcd259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3a808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aee20468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "88bf2499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672adf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fad156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
